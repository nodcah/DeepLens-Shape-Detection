{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "psychological-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "INFO:tensorflow:Disabling tensor equality\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import keras2onnx\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-shopping",
   "metadata": {},
   "source": [
    "## Reading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "found-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_root = 'shapes/shapes'\n",
    "shape_names = ['circle/','square/','star/','triangle/']\n",
    "shape_class_labels = np.array([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescription-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from shapes_root and form into numpy array\n",
    "N = sum([len(files) for _, _, files in os.walk(shape_root)])-1\n",
    "count = 0\n",
    "\n",
    "X = np.zeros((N,32,32,1)) # 3D array of x,y,#images of shape (N,32,32)\n",
    "Y = np.zeros(N) # vector of class labels\n",
    "\n",
    "\n",
    "\n",
    "for label,shape_name in enumerate(shape_names):\n",
    "    shape_path = os.path.join(shape_root,shape_name)\n",
    "\n",
    "    num = 0\n",
    "    image_path = os.path.join(shape_path,f'{num}.png')\n",
    "    while os.path.isfile(image_path):\n",
    "        img = Image.open(image_path)\n",
    "        X[count,:,:,0] = np.array(img.resize((32,32))) # downsample image to 32x32 #,resample=Image.NEAREST)\n",
    "        Y[count] = label\n",
    "        num += 1\n",
    "        count += 1\n",
    "        image_path = os.path.join(shape_path,f'{num}.png')\n",
    "Y_onehot = tf.keras.utils.to_categorical(Y,num_classes=4,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "retired-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14970"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into testing/training TODO\n",
    "plt.imshow(X[14961,:,:,0],cmap='gray')\n",
    "plt.show()\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-treasury",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pregnant-illness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 340       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 61,196\n",
      "Trainable params: 61,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(32,32,1)))\n",
    "model.add(layers.Conv2D(6,5,activation='relu'))   # 6 filters with 5x5 kernal; outputs 6@28x28\n",
    "model.add(layers.MaxPooling2D((2,2)))             # max pooling with 2x2 pool size; outputs 6@14x14\n",
    "model.add(layers.Conv2D(16,5,activation='relu'))  # 16 filters with 5x5 kernal; outputs 16@10x10\n",
    "model.add(layers.MaxPooling2D((2,2)))             # max pooling with 2x2 pool size; outputs 16@5x5\n",
    "model.add(layers.Conv2D(120,5,activation='relu')) # 120 filters with 5x5 kernal; outputs 120@1x1\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation='relu'))    # fully connected layer; outputs 84\n",
    "model.add(layers.Dense(4, activation='relu'))     # fully connected layer; outputs 4\n",
    "model.add(layers.Softmax())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-crowd",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "secondary-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14970, 32, 32, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "casual-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14970,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brief-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 144ms/step - loss: 1.3863 - accuracy: 0.2734 - val_loss: 1.3863 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-26b37b140a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save as ONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mkeras2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras2onnx/main.py\u001b[0m in \u001b[0;36mconvert_keras\u001b[0;34m(model, name, doc_string, target_opset, channel_first_inputs, debug_mode, custom_op_conversions)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_tf2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_keras\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtf_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_layer_output_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtf_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras2onnx/_parser_tf.py\u001b[0m in \u001b[0;36mbuild_layer_output_from_model\u001b[0;34m(model, output_dict, input_names, output_names)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mextract_outputs_from_subclassing_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0moutput_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_outputs_from_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "# Compile and fit model\n",
    "opt = Adam(learning_rate=.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= opt, metrics= [\"accuracy\"])\n",
    "model.fit(\n",
    "    X,Y_onehot,\n",
    "    batch_size=1000,\n",
    "    epochs=1,\n",
    "    validation_split=.1\n",
    ")\n",
    "\n",
    "# Save as ONNX\n",
    "onnx_model = keras2onnx.convert_keras(model)\n",
    "keras2onnx.save_model(onnx_model,'model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-converter",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display output of network on a query image \n",
    "# (will eventually be copied to another file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
